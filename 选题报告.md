<h1 style="text-align: center;">开题报告</h1>

<div style="text-align: center; font-weight: bold;">
    研究主题：基于动态计算框架的神经网络算子并行加速库——mytorch
</div>

### **选题及基本信息**

**主题：**

**团队成员信息：**（顺序无先后之分）

| 姓名   | 学号     |
| ------ | -------- |
| 陈兴平 | 22336037 |
| 刘华壹 | 22336149 |
| 罗弘杰 | 22336173         |
>>>>>>> 4620ddb56d716ecb85f1d8b01d7b88eede98be8a

**团队协作方式：**通过 Github  的私有仓库，共同编辑代码以及报告。

### **选题说明**

#### **1. 选题背景**

深度学习的热潮开始与AlexNet开始，随着数据和算力的不断提高，科研和工程领域急需要深度学习框架加速模型开发和部署。由于深度学习主要设计矩阵的一系列计算，非常适合运用并行算法以及并行框架加速相关算子的计算。从Caffe,Tensorflow, 到PyTorch, DLF经过十年的发展，从创新各起，到PyTorch开始占据主流，到今天已经超过了50%以上的深度学习github repo由PyTorch开发。
![alt text](/static/ComparisonOfDLF.png)
虽然大部分的框架都是开源的，但是对于国产化的设备，比如摩尔线程，华为，寒武纪的计算卡，PyTorch相关的适配并不完善。同时随着大模型的快速发展，一些新的算子适配比较慢，比如FlashAttention, 企业有内部定制算子的需求。
#### **2. 相关工作**

> 因为我们的研究主要基于pytorch，所以主要介绍pytorch相关的情况
>
> 第二点简单介绍一些前沿论文通过调整或者写底层算子来实现加速的例子。比如deepseek团队提出的一些节约硬件开销的加速方方法



**2.1 pytorch**

在当今神经网络研究领域，PyTorch已成为不可或缺的核心工具。作为Meta（原Facebook）开发的开源框架，它凭借动态图优先的设计哲学脱颖而出，通过`torch.autograd`在Python运行时动态构建计算图，这种机制相比TensorFlow等静态图框架更能满足科研场景的快速迭代需求。PyTorch不仅提供直观的Pythonic编程体验和高效的GPU加速能力，还集成了完整的深度学习工具链（如TorchVision、TorchText），并与Python生态无缝对接，同时通过TorchScript和ONNX支持实现便捷的模型部署。随着PyTorch 2.0引入编译优化技术并持续强化分布式训练与大模型支持（如Llama），该框架在保持科研灵活性的同时不断提升工业级性能，已成为贯穿算法探索到生产落地的首选平台。

以下是 pytorch 的框架图（使用 Mermaid 代码编写）：

```mermaid
graph TD
    subgraph Python接口
        TorchAPI["torch (核心API)"]
        TorchNN["torch.nn (神经网络层)"]
        TorchAutograd["torch.autograd (自动微分)"]
        TorchOptim["torch.optim (优化器)"]
        TorchDistributed["torch.distributed (分布式)"]
        TorchJIT["torch.jit (JIT编译器接口)"]
    end

    subgraph 底层C++实现
        TorchC["torch._C (C++核心)"]
        TorchCSRC["torch/csrc (C++扩展)"]
        JITImpl["torch/csrc/jit (JIT核心)"]
        ATen["aten (Tensor和算子实现)"]
        C10["c10 (通用基础库)"]
    end

    subgraph 编译与加速
        Dynamo["torch.compile & Dynamo编译器"]
        Inductor["TorchInductor (高性能后端)"]
    end

    subgraph 工具与文档
        Docs["docs/ (文档)"]
        Tools["tools/ (开发与CI工具)"]
    end

    TorchAPI --> TorchNN
    TorchAPI --> TorchAutograd
    TorchAPI --> TorchOptim
    TorchAPI --> TorchDistributed
    TorchAPI --> TorchJIT

    TorchAPI --> TorchC
    TorchNN --> TorchC
    TorchAutograd --> TorchC
    TorchOptim --> TorchC
    TorchDistributed --> TorchC
    TorchJIT --> JITImpl

    TorchC --> ATen
    TorchC --> C10
    TorchCSRC --> ATen
    TorchCSRC --> C10

    TorchJIT --> JITImpl

    TorchAPI --> Dynamo
    Dynamo --> Inductor

    Docs -.-> TorchAPI
    Docs -.-> TorchC
    Tools -.-> TorchAPI
    Tools -.-> TorchC

```

**2.2 前沿**



#### **3. 研究意义**

> 对了解pytorch的实现，应用我们的并行知识有很大的帮助，而且在错综复杂的国际形势下，提出更好的加速方案以及计算框架国产化具有非凡的意义。（就是从个人到国家的角度简单说明）



### **预期成果**

因为选题实现的复杂程度及难度较大，暂不知道能做到什么层次的成果。故我们的预期结果采用分层方式展现。

- **初级目标：**
  - [ ] 学习并复现 pytorch 的相关基础代码，比如张量构建、数据处理等
  - [ ] 实现一个全连接层网络的训练相关代码
- **中级目标：**
  - [ ] 了解并实现分布式并行内容，支持多卡运算
  - [ ] 设计一些个性化算子以支持实际应用，并取得加速效果
  - [ ] 完成神经网络，自动微分以及优化器的API的设计和实现

- **高级目标：**
  - [ ] 形成一个相对完整的计算框架
  - [ ] 针对Transformer架构实现融合算子，取得训练和推理速度的提升
  - [ ] 尝试通过算子优化等方式，来加速前沿论文模型


### **参考资料**

- [[1912.01703\] PyTorch: An Imperative Style, High-Performance Deep Learning Library](https://arxiv.org/abs/1912.01703)
- [[2401.06066\] DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://arxiv.org/abs/2401.06066)
- [[2412.19437\] DeepSeek-V3 Technical Report](https://arxiv.org/abs/2412.19437)
- [pytorch/pytorch: Tensors and Dynamic neural networks in Python with strong GPU acceleration](https://github.com/pytorch/pytorch)
- [pytorch源码介绍-视频合集-哔哩哔哩视频](https://space.bilibili.com/373596439/lists?sid=57707&spm_id_from=333.788.0.0)





